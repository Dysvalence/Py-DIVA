{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 960 (CNMeM is enabled with initial size: 70.0% of memory, cuDNN 4007)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Runs a normal DIVA on MNIST.\n",
    "\"\"\"\n",
    "\n",
    "import DIVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this cell is taken almost verbatim from the keras examples.\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam #, RMSprop #Rmsprop doesn't work well\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Loss 4502.044252\n",
      "Test Accuracy: 0.845300\n",
      "Epoch 2\n",
      "Loss 2924.729366\n",
      "Test Accuracy: 0.859100\n",
      "Epoch 3\n",
      "Loss 2697.729527\n",
      "Test Accuracy: 0.879200\n",
      "Epoch 4\n",
      "Loss 2503.038682\n",
      "Test Accuracy: 0.896500\n",
      "Epoch 5\n",
      "Loss 2337.448218\n",
      "Test Accuracy: 0.912000\n",
      "Epoch 6\n",
      "Loss 2201.188217\n",
      "Test Accuracy: 0.923600\n",
      "Epoch 7\n",
      "Loss 2087.585899\n",
      "Test Accuracy: 0.930800\n",
      "Epoch 8\n",
      "Loss 1990.531569\n",
      "Test Accuracy: 0.937800\n",
      "Epoch 9\n",
      "Loss 1905.956289\n",
      "Test Accuracy: 0.943000\n",
      "Epoch 10\n",
      "Loss 1831.111796\n",
      "Test Accuracy: 0.945700\n",
      "Epoch 11\n",
      "Loss 1764.003225\n",
      "Test Accuracy: 0.949300\n",
      "Epoch 12\n",
      "Loss 1703.161723\n",
      "Test Accuracy: 0.952100\n",
      "Epoch 13\n",
      "Loss 1647.486632\n",
      "Test Accuracy: 0.952900\n",
      "Epoch 14\n",
      "Loss 1596.140170\n",
      "Test Accuracy: 0.954300\n",
      "Epoch 15\n",
      "Loss 1548.499451\n",
      "Test Accuracy: 0.955000\n",
      "Epoch 16\n",
      "Loss 1504.096701\n",
      "Test Accuracy: 0.956300\n",
      "Epoch 17\n",
      "Loss 1462.573398\n",
      "Test Accuracy: 0.956400\n",
      "Epoch 18\n",
      "Loss 1423.643614\n",
      "Test Accuracy: 0.957400\n",
      "Epoch 19\n",
      "Loss 1387.096564\n",
      "Test Accuracy: 0.958500\n",
      "Epoch 20\n",
      "Loss 1352.731927\n",
      "Test Accuracy: 0.958800\n",
      "Epoch 21\n",
      "Loss 1320.376535\n",
      "Test Accuracy: 0.958800\n",
      "Epoch 22\n",
      "Loss 1289.878509\n",
      "Test Accuracy: 0.959500\n",
      "Epoch 23\n",
      "Loss 1261.099806\n",
      "Test Accuracy: 0.958900\n",
      "Epoch 24\n",
      "Loss 1233.920450\n",
      "Test Accuracy: 0.958500\n",
      "Epoch 25\n",
      "Loss 1208.221401\n",
      "Test Accuracy: 0.958600\n",
      "Epoch 26\n",
      "Loss 1183.890729\n",
      "Test Accuracy: 0.958900\n",
      "Epoch 27\n",
      "Loss 1160.834380\n",
      "Test Accuracy: 0.959200\n",
      "Epoch 28\n",
      "Loss 1138.963281\n",
      "Test Accuracy: 0.959200\n",
      "Epoch 29\n",
      "Loss 1118.186774\n",
      "Test Accuracy: 0.959200\n",
      "Epoch 30\n",
      "Loss 1098.425856\n",
      "Test Accuracy: 0.958700\n",
      "Epoch 31\n",
      "Loss 1079.608084\n",
      "Test Accuracy: 0.958900\n",
      "Epoch 32\n",
      "Loss 1061.664501\n",
      "Test Accuracy: 0.959400\n",
      "Epoch 33\n",
      "Loss 1044.538431\n",
      "Test Accuracy: 0.959000\n",
      "Epoch 34\n",
      "Loss 1028.176604\n",
      "Test Accuracy: 0.959000\n",
      "Epoch 35\n",
      "Loss 1012.525609\n",
      "Test Accuracy: 0.958900\n",
      "Epoch 36\n",
      "Loss 997.536228\n",
      "Test Accuracy: 0.958300\n",
      "Epoch 37\n",
      "Loss 983.165978\n",
      "Test Accuracy: 0.958200\n",
      "Epoch 38\n",
      "Loss 969.373218\n",
      "Test Accuracy: 0.958100\n",
      "Epoch 39\n",
      "Loss 956.121809\n",
      "Test Accuracy: 0.957800\n",
      "Epoch 40\n",
      "Loss 943.377523\n",
      "Test Accuracy: 0.957800\n",
      "Epoch 41\n",
      "Loss 931.107195\n",
      "Test Accuracy: 0.957500\n",
      "Epoch 42\n",
      "Loss 919.281738\n",
      "Test Accuracy: 0.957500\n",
      "Epoch 43\n",
      "Loss 907.874669\n",
      "Test Accuracy: 0.957000\n",
      "Epoch 44\n",
      "Loss 896.862302\n",
      "Test Accuracy: 0.956700\n",
      "Epoch 45\n",
      "Loss 886.220103\n",
      "Test Accuracy: 0.957000\n",
      "Epoch 46\n",
      "Loss 875.926629\n",
      "Test Accuracy: 0.956600\n",
      "Epoch 47\n",
      "Loss 865.962548\n",
      "Test Accuracy: 0.956200\n",
      "Epoch 48\n",
      "Loss 856.310282\n",
      "Test Accuracy: 0.956000\n",
      "Epoch 49\n",
      "Loss 846.952380\n",
      "Test Accuracy: 0.956300\n",
      "Epoch 50\n",
      "Loss 837.873204\n",
      "Test Accuracy: 0.956600\n",
      "Done training\n",
      "Test Accuracy: 0.956600\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "nb_classes = 10\n",
    "nb_epoch = 50\n",
    "input_shape = 784\n",
    "num_hidden = 500\n",
    "\n",
    "#compile model\n",
    "diva_model = DIVA.diva(nb_classes, input_shape, num_hidden, hidden_act='relu', \n",
    "                       loss='mean_squared_error', optimizer=SGD(), compare=DIVA.compareMSE)\n",
    "\n",
    "#train model\n",
    "train_metrics=diva_model.train(X_train, y_train, nb_epoch, 1, X_test, y_test)            \n",
    "            \n",
    "#test model\n",
    "accuracy=diva_model.test(X_test, y_test, 1) \n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Loss 829.059082\n",
      "Test Accuracy: 0.956200\n",
      "Epoch 2\n"
     ]
    }
   ],
   "source": [
    "#run this cell for more training. Note that epoch counter resets.\n",
    "train_metrics=diva_model.train(X_train, y_train, nb_epoch, 1, X_test, y_test)            \n",
    "            \n",
    "accuracy=diva_model.test(X_test, y_test, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: graph loss and accuracy in matplotlib"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
